{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fbefb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e02f9026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_3692\\3364100549.py:1: DtypeWarning: Columns (4,27,29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"DataJobseeker.csv\", encoding='ISO-8859-1')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>js_unique_id</th>\n",
       "      <th>request_date</th>\n",
       "      <th>daily_serial_no</th>\n",
       "      <th>eng_name_of_js</th>\n",
       "      <th>phone_no_js</th>\n",
       "      <th>js_email</th>\n",
       "      <th>js_request_ip_address</th>\n",
       "      <th>generated_1st_pwd</th>\n",
       "      <th>pwd_sent_mode</th>\n",
       "      <th>pwd_sent_date</th>\n",
       "      <th>...</th>\n",
       "      <th>usernameEdistrict</th>\n",
       "      <th>AadharFlag</th>\n",
       "      <th>Dob</th>\n",
       "      <th>gender</th>\n",
       "      <th>Aadhar_verify_dt</th>\n",
       "      <th>CheckFlag</th>\n",
       "      <th>userreg</th>\n",
       "      <th>insertdate</th>\n",
       "      <th>NewPassword</th>\n",
       "      <th>NewPassFlag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4848316</td>\n",
       "      <td>2016/03/01</td>\n",
       "      <td>1</td>\n",
       "      <td>RAJ KUMAR</td>\n",
       "      <td>8127302578</td>\n",
       "      <td>shiva.herbal26@gmail.com</td>\n",
       "      <td>59.97.88.199</td>\n",
       "      <td>81dc9bdb52d04dc20036dbd8313ed055</td>\n",
       "      <td>B</td>\n",
       "      <td>2016/03/03</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>4848317</td>\n",
       "      <td>2016/03/01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4848515</td>\n",
       "      <td>2015/05/01</td>\n",
       "      <td>1</td>\n",
       "      <td>Dilip Kumar</td>\n",
       "      <td>6307263126</td>\n",
       "      <td>dk680871@gmail.com</td>\n",
       "      <td>117.201.54.148</td>\n",
       "      <td>c9d20dfa5c0dd98bc81dc145917edd87</td>\n",
       "      <td>B</td>\n",
       "      <td>2015/05/01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>1/1/1996</td>\n",
       "      <td>M</td>\n",
       "      <td>2024/07/12</td>\n",
       "      <td>O</td>\n",
       "      <td>4848516</td>\n",
       "      <td>2015/05/01</td>\n",
       "      <td>4fb76767efb5686f344ec742802cac47635e0130c265bd...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4814815</td>\n",
       "      <td>01-48-2015</td>\n",
       "      <td>1</td>\n",
       "      <td>ABHIKESH</td>\n",
       "      <td>8081643688</td>\n",
       "      <td>abhikeshverma4321@gmail.com</td>\n",
       "      <td>481.212.71.481</td>\n",
       "      <td>df8ed725770e25ca30f27173a3b62aef</td>\n",
       "      <td>B</td>\n",
       "      <td>01-48-2015  00:01:05</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>4814816</td>\n",
       "      <td>01-48-2015  00:00:00</td>\n",
       "      <td>4a3e18fg09438edf6c48764d35e147d801a3b55cc06b54...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4820216</td>\n",
       "      <td>2016/02/02</td>\n",
       "      <td>1</td>\n",
       "      <td>GULZAR AHMAD</td>\n",
       "      <td>7266044877</td>\n",
       "      <td>nadeemmau2016@gmail.com</td>\n",
       "      <td>1.39.48.144</td>\n",
       "      <td>55017a6dfdca3a0cc433c9a2c96ef31c</td>\n",
       "      <td>B</td>\n",
       "      <td>2016/02/02</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>4820217</td>\n",
       "      <td>2016/02/02</td>\n",
       "      <td>4a3e18fg09438edf6c48764d35e147d801a3b55cc06b54...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4820515</td>\n",
       "      <td>2015/05/02</td>\n",
       "      <td>1</td>\n",
       "      <td>RAHUL RATHOUR</td>\n",
       "      <td>7607412349</td>\n",
       "      <td>eapulrathourboss@gmail.com</td>\n",
       "      <td>37.228.485.63</td>\n",
       "      <td>a1ca5b6655ea0dba2dea6a6b5b5d8f14</td>\n",
       "      <td>B</td>\n",
       "      <td>2015/05/02</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>4820516</td>\n",
       "      <td>2015/05/02</td>\n",
       "      <td>4a3e18fg09438edf6c48764d35e147d801a3b55cc06b54...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>1455180815</td>\n",
       "      <td>2015/08/18</td>\n",
       "      <td>1455</td>\n",
       "      <td>MAHENDRA VISHWKARMA</td>\n",
       "      <td>8853727261</td>\n",
       "      <td>mahendravishwakarma2@gmail.com</td>\n",
       "      <td>122.163.238.211</td>\n",
       "      <td>b42136d96658ad0a8d9cec101dbc1423</td>\n",
       "      <td>B</td>\n",
       "      <td>2015/08/18</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>1455182270</td>\n",
       "      <td>2015/08/18</td>\n",
       "      <td>4a3e18fg09438edf6c10764d35e147d801a3b55cc06b54...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>1455190216</td>\n",
       "      <td>2016/02/19</td>\n",
       "      <td>1455</td>\n",
       "      <td>ZIA TASNEEM</td>\n",
       "      <td>8423705426</td>\n",
       "      <td>om@yahoo.com</td>\n",
       "      <td>1.39.51.243</td>\n",
       "      <td>202ca662ac59075a664b07152d234b70</td>\n",
       "      <td>B</td>\n",
       "      <td>2016/02/19</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>1455191671</td>\n",
       "      <td>2016/02/19</td>\n",
       "      <td>4a3e18fg09438edf6c10764d35e147d801a3b55cc06b54...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>1455190615</td>\n",
       "      <td>2015/06/19</td>\n",
       "      <td>1455</td>\n",
       "      <td>SUDHIR KUMAR SUMAN</td>\n",
       "      <td>9451211140</td>\n",
       "      <td>sudhir.1187@rediffmail.com</td>\n",
       "      <td>106.219.0.30</td>\n",
       "      <td>4a0c0b3c4a9b0448806a2dccdebacf04</td>\n",
       "      <td>B</td>\n",
       "      <td>2015/06/19</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>1455192070</td>\n",
       "      <td>2015/06/19</td>\n",
       "      <td>4a3e18fg09438edf6c10764d35e147d801a3b55cc06b54...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>1455200316</td>\n",
       "      <td>2016/03/20</td>\n",
       "      <td>1455</td>\n",
       "      <td>SAID AHMAD</td>\n",
       "      <td>8869820800</td>\n",
       "      <td>sayeed.ahmad1985@gmail.com</td>\n",
       "      <td>112.110.23.143</td>\n",
       "      <td>e10adc3949ba59abbe56e057f20f883e</td>\n",
       "      <td>B</td>\n",
       "      <td>2016/03/20</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>1455201771</td>\n",
       "      <td>2016/03/20</td>\n",
       "      <td>4a3e18fg09438edf6c10764d35e147d801a3b55cc06b54...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>1455210116</td>\n",
       "      <td>2016/01/21</td>\n",
       "      <td>1455</td>\n",
       "      <td>PRASHANT KUMAR</td>\n",
       "      <td>9616485914</td>\n",
       "      <td>rajeshcomputergnj@gmail.com</td>\n",
       "      <td>1.39.48.60</td>\n",
       "      <td>79cfac6387ee1882f83a29a04d0bcdc4</td>\n",
       "      <td>B</td>\n",
       "      <td>2016/01/21</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>1455211571</td>\n",
       "      <td>2016/01/21</td>\n",
       "      <td>4a3e18fg09438edf6c10764d35e147d801a3b55cc06b54...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       js_unique_id request_date  daily_serial_no       eng_name_of_js  \\\n",
       "0           4848316   2016/03/01                1            RAJ KUMAR   \n",
       "1           4848515   2015/05/01                1          Dilip Kumar   \n",
       "2           4814815   01-48-2015                1             ABHIKESH   \n",
       "3           4820216   2016/02/02                1         GULZAR AHMAD   \n",
       "4           4820515   2015/05/02                1        RAHUL RATHOUR   \n",
       "...             ...          ...              ...                  ...   \n",
       "99995    1455180815   2015/08/18             1455  MAHENDRA VISHWKARMA   \n",
       "99996    1455190216   2016/02/19             1455          ZIA TASNEEM   \n",
       "99997    1455190615   2015/06/19             1455   SUDHIR KUMAR SUMAN   \n",
       "99998    1455200316   2016/03/20             1455           SAID AHMAD   \n",
       "99999    1455210116   2016/01/21             1455       PRASHANT KUMAR   \n",
       "\n",
       "      phone_no_js                        js_email js_request_ip_address  \\\n",
       "0      8127302578        shiva.herbal26@gmail.com          59.97.88.199   \n",
       "1      6307263126              dk680871@gmail.com        117.201.54.148   \n",
       "2      8081643688     abhikeshverma4321@gmail.com        481.212.71.481   \n",
       "3      7266044877         nadeemmau2016@gmail.com           1.39.48.144   \n",
       "4      7607412349      eapulrathourboss@gmail.com         37.228.485.63   \n",
       "...           ...                             ...                   ...   \n",
       "99995  8853727261  mahendravishwakarma2@gmail.com       122.163.238.211   \n",
       "99996  8423705426                    om@yahoo.com           1.39.51.243   \n",
       "99997  9451211140      sudhir.1187@rediffmail.com          106.219.0.30   \n",
       "99998  8869820800      sayeed.ahmad1985@gmail.com        112.110.23.143   \n",
       "99999  9616485914     rajeshcomputergnj@gmail.com            1.39.48.60   \n",
       "\n",
       "                      generated_1st_pwd pwd_sent_mode         pwd_sent_date  \\\n",
       "0      81dc9bdb52d04dc20036dbd8313ed055             B            2016/03/03   \n",
       "1      c9d20dfa5c0dd98bc81dc145917edd87             B            2015/05/01   \n",
       "2      df8ed725770e25ca30f27173a3b62aef             B  01-48-2015  00:01:05   \n",
       "3      55017a6dfdca3a0cc433c9a2c96ef31c             B            2016/02/02   \n",
       "4      a1ca5b6655ea0dba2dea6a6b5b5d8f14             B            2015/05/02   \n",
       "...                                 ...           ...                   ...   \n",
       "99995  b42136d96658ad0a8d9cec101dbc1423             B            2015/08/18   \n",
       "99996  202ca662ac59075a664b07152d234b70             B            2016/02/19   \n",
       "99997  4a0c0b3c4a9b0448806a2dccdebacf04             B            2015/06/19   \n",
       "99998  e10adc3949ba59abbe56e057f20f883e             B            2016/03/20   \n",
       "99999  79cfac6387ee1882f83a29a04d0bcdc4             B            2016/01/21   \n",
       "\n",
       "       ... usernameEdistrict AadharFlag       Dob gender Aadhar_verify_dt  \\\n",
       "0      ...               NaN        NaN       NaN    NaN              NaN   \n",
       "1      ...               NaN          Y  1/1/1996      M       2024/07/12   \n",
       "2      ...               NaN        NaN       NaN    NaN              NaN   \n",
       "3      ...               NaN        NaN       NaN    NaN              NaN   \n",
       "4      ...               NaN        NaN       NaN    NaN              NaN   \n",
       "...    ...               ...        ...       ...    ...              ...   \n",
       "99995  ...               NaN        NaN       NaN    NaN              NaN   \n",
       "99996  ...               NaN        NaN       NaN    NaN              NaN   \n",
       "99997  ...               NaN        NaN       NaN    NaN              NaN   \n",
       "99998  ...               NaN        NaN       NaN    NaN              NaN   \n",
       "99999  ...               NaN        NaN       NaN    NaN              NaN   \n",
       "\n",
       "      CheckFlag     userreg            insertdate  \\\n",
       "0             O     4848317            2016/03/01   \n",
       "1             O     4848516            2015/05/01   \n",
       "2             O     4814816  01-48-2015  00:00:00   \n",
       "3             O     4820217            2016/02/02   \n",
       "4             O     4820516            2015/05/02   \n",
       "...         ...         ...                   ...   \n",
       "99995         O  1455182270            2015/08/18   \n",
       "99996         O  1455191671            2016/02/19   \n",
       "99997         O  1455192070            2015/06/19   \n",
       "99998         O  1455201771            2016/03/20   \n",
       "99999         O  1455211571            2016/01/21   \n",
       "\n",
       "                                             NewPassword NewPassFlag  \n",
       "0                                                    NaN         NaN  \n",
       "1      4fb76767efb5686f344ec742802cac47635e0130c265bd...           C  \n",
       "2      4a3e18fg09438edf6c48764d35e147d801a3b55cc06b54...           C  \n",
       "3      4a3e18fg09438edf6c48764d35e147d801a3b55cc06b54...           C  \n",
       "4      4a3e18fg09438edf6c48764d35e147d801a3b55cc06b54...           C  \n",
       "...                                                  ...         ...  \n",
       "99995  4a3e18fg09438edf6c10764d35e147d801a3b55cc06b54...           C  \n",
       "99996  4a3e18fg09438edf6c10764d35e147d801a3b55cc06b54...           C  \n",
       "99997  4a3e18fg09438edf6c10764d35e147d801a3b55cc06b54...           C  \n",
       "99998  4a3e18fg09438edf6c10764d35e147d801a3b55cc06b54...           C  \n",
       "99999  4a3e18fg09438edf6c10764d35e147d801a3b55cc06b54...           C  \n",
       "\n",
       "[100000 rows x 43 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"DataJobseeker.csv\", encoding='ISO-8859-1')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b904bc8",
   "metadata": {},
   "source": [
    "| **Column**                               | **Description**                               |\n",
    "| ---------------------------------------- | --------------------------------------------- |\n",
    "| `js_unique_id`                           | Unique identifier for each job seeker         |\n",
    "| `request_date`                           | Date of registration request                  |\n",
    "| `daily_serial_no`                        | Daily sequence number                         |\n",
    "| `eng_name_of_js`                         | Full name of the job seeker                   |\n",
    "| `phone_no_js`, `js_email`                | Contact info                                  |\n",
    "| `js_request_ip_address`                  | IP address used for registration              |\n",
    "| `generated_1st_pwd`                      | Hashed password initially generated           |\n",
    "| `pwd_sent_mode`, `pwd_sent_date`         | Mode/date of password delivery                |\n",
    "| `js_first_log_date`                      | First login date                              |\n",
    "| `LastloginDate`, `LoginAttempts`         | Login behavior tracking                       |\n",
    "| `lock`, `NewPassword`, `NewPassFlag`     | Password status and login lock indicators     |\n",
    "| `prf_submitted`, `final_submittion_date` | Whether profile was completed and when        |\n",
    "| `satyapan_done`, `aft_satyapan_login_dt` | Aadhaar-based verification completed and when |\n",
    "| `AadharFlag`, `Aadhar_verify_dt`         | Aadhaar verified or not, and date             |\n",
    "| `Dob`, `gender`                          | Demographics                                  |\n",
    "| `insertdate`                             | Date when this record was added to the system |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b709f8",
   "metadata": {},
   "source": [
    "### Convert string columns to datetime format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d1f07e",
   "metadata": {},
   "source": [
    "#### Handle request_date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dc90ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valid dates will be converted properly to yyyy-mm-dd format\n",
    "df['clean_request_date'] = pd.to_datetime(df['request_date'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451d1a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many rows were not converted\n",
    "df['clean_request_date'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44178ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See bad date strings\n",
    "df[df['clean_request_date'].isna() & df['request_date'].notna()]['request_date'].value_counts()\n",
    "\n",
    "# df['clean_request_date'].isna() - gave all the NaT rows from the 'clean_request_date' column\n",
    "# df['request_date'].notna() - give all the rows that are not NULL in 'request_date'\n",
    "# combining them ensures that we get only invalid values and not NULL values\n",
    "# ['request_date'] - Pulls out just the original raw date values from those bad rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1207044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understand the overall situation of the dataset i.e. how many columns of that row are null and what do they contain\n",
    "df[df['clean_request_date'].isna()].describe(include='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056c0020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract top wrong dates and undertand the common pattern\n",
    "bad_dates = df[df['clean_request_date'].isna()]['request_date'].value_counts().head(15)\n",
    "print(bad_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b202083a",
   "metadata": {},
   "source": [
    "SUMMARY- <br>\n",
    "- around 850 rows have 48 in beginning \n",
    "- around 1100 rows have 48 as their middle value\n",
    "- by handling these 2 problems we can make a large number of rows from invalid ones again useful \n",
    "- These are likely typos where 48 should’ve been a valid day\n",
    "- **Strategy:** Replace '48-' with '04-' or '08-' based on context. You can assume the most common intended value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eebd934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Fix request_date values starting with '48' → replace '48' with '08'\n",
    "mask_start_48 = df['request_date'].str.startswith('48', na=False)\n",
    "df.loc[mask_start_48, 'clean_request_date'] = pd.to_datetime(\n",
    "    df.loc[mask_start_48, 'request_date']\n",
    "    .str.replace('--', '-', regex=False)\n",
    "    .str.replace(r'^48', '08', regex=True),\n",
    "    errors='coerce',\n",
    "    dayfirst=True\n",
    ")\n",
    "\n",
    "# Step 2: Fix values where '48' is in the middle (but NOT those already handled in step 1)\n",
    "mask_middle_48 = df['request_date'].str.contains('48', na=False) & ~mask_start_48\n",
    "df.loc[mask_middle_48, 'clean_request_date'] = pd.to_datetime(\n",
    "    df.loc[mask_middle_48, 'request_date']\n",
    "    .str.replace('--', '-', regex=False)  # fix double hyphens\n",
    "    .str.replace(r'-(48)-', '-08-', regex=True),\n",
    "    errors='coerce',\n",
    "    dayfirst=True\n",
    ")\n",
    "\n",
    "# Step 3: Fix values with '48' at both start and middle (but NOT those already handled in step 1 and 2)\n",
    "mask_both_48 = df['request_date'].str.startswith('48', na=False) & df['request_date'].str.contains('48', na=False)\n",
    "df.loc[mask_both_48, 'clean_request_date'] = pd.to_datetime(\n",
    "    df.loc[mask_both_48, 'request_date']\n",
    "    .str.replace('--', '-', regex=False)\n",
    "    .str.replace(r'^48', '08', regex=True)\n",
    "    .str.replace(r'-(48)-', '-08-', regex=True),\n",
    "    errors='coerce',\n",
    "    dayfirst=True\n",
    ")\n",
    "\n",
    "# Step-3 was written after executing the above 2 steps to understand how many rows are remaining and is there any pattern in them\n",
    "# conclusion was that only those rows that have '48' at both start and middle were remaining so we handled them as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d64c38eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_request_date'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd25be1",
   "metadata": {},
   "source": [
    "#### Handle pwd_sent_date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0179ecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valid dates will be converted properly to yyyy-mm-dd format\n",
    "df['clean_pwd_sent_date'] = pd.to_datetime(df['pwd_sent_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f0b538b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(4121)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many rows were not converted\n",
    "df['clean_pwd_sent_date'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79128675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pwd_sent_date\n",
       "48-03-2016  48:22:01    2\n",
       "29-48-2015  48:11:26    2\n",
       "48-05-2015  48:29:00    2\n",
       "48-03-2016  11:02:06    2\n",
       "31-48-2015  07:09:00    2\n",
       "                       ..\n",
       "19-48-2015  09:52:59    1\n",
       "20-48-2015  48:04:45    1\n",
       "21-48-2015  48:13:49    1\n",
       "25-48-2015  11:48:15    1\n",
       "29-48-2015  11:17:57    1\n",
       "Name: count, Length: 4098, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See bad date strings\n",
    "df[df['clean_pwd_sent_date'].isna() & df['pwd_sent_date'].notna()]['pwd_sent_date'].value_counts()\n",
    "\n",
    "# df['clean_pwd_sent_date'].isna() - gave all the NaT rows from the 'clean_pwd_sent_date' column\n",
    "# df['pwd_sent_date'].notna() - give all the rows that are not NULL in 'request_date'\n",
    "# combining them ensures that we get only invalid values and not NULL values\n",
    "# ['pwd_sent_date'] - Pulls out just the original raw date values from those bad rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741a9d35",
   "metadata": {},
   "source": [
    "SUMMARY- <br>\n",
    "- several rows have 48 in beginning and in middle\n",
    "- by handling these 2 problems we can make a large number of rows from invalid ones again useful \n",
    "- These are likely typos where 48 should’ve been a valid day\n",
    "- **Strategy:** Replace '48-' with '04-' or '08-' based on context. You can assume the most common intended value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55aee14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Fix pwd_sent_date values starting with '48' → replace '48' with '04', then remove time\n",
    "mask_start_48 = df['pwd_sent_date'].str.startswith('48', na=False)\n",
    "df.loc[mask_start_48, 'clean_pwd_sent_date'] = pd.to_datetime(\n",
    "    df.loc[mask_start_48, 'pwd_sent_date']\n",
    "    .str.replace(r'^48', '04', regex=True)       # replace starting 48 with 04\n",
    "    .str.extract(r'(\\d{2}-\\d{2}-\\d{4})')[0],      # extract only the date part\n",
    "    errors='coerce',\n",
    "    dayfirst=True\n",
    ")\n",
    "\n",
    "# Step 2: Fix values where '48' is in the **middle** (not already handled in step 1), then remove time\n",
    "mask_middle_48 = df['pwd_sent_date'].str.contains('48', na=False) & ~mask_start_48\n",
    "df.loc[mask_middle_48, 'clean_pwd_sent_date'] = pd.to_datetime(\n",
    "    df.loc[mask_middle_48, 'pwd_sent_date']\n",
    "    .str.replace('--', '-', regex=False)  # fix double hyphens\n",
    "    .str.replace(r'-(48)-', '-08-', regex=True)\n",
    "    .str.extract(r'(\\d{2}-\\d{2}-\\d{4})')[0],\n",
    "    errors='coerce',\n",
    "    dayfirst=True\n",
    ")\n",
    "\n",
    "# Step 3: Fix values with '48' at both start and middle (but NOT those already handled in step 1 and 2)\n",
    "mask_both_48 = df['pwd_sent_date'].str.startswith('48', na=False) & df['pwd_sent_date'].str.contains('48', na=False)\n",
    "df.loc[mask_both_48, 'clean_pwd_sent_date'] = pd.to_datetime(\n",
    "    df.loc[mask_both_48, 'pwd_sent_date']\n",
    "    .str.replace(r'^48', '08', regex=True)\n",
    "    .str.replace(r'-(48)-', '-08-', regex=True)\n",
    "    .str.extract(r'(\\d{2}-\\d{2}-\\d{4})')[0],\n",
    "    errors='coerce',\n",
    "    dayfirst=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edcfa0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_pwd_sent_date'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174bbf0e",
   "metadata": {},
   "source": [
    "#### Handle js_first_log_date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f80cea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valid dates will be converted properly to yyyy-mm-dd format\n",
    "df['clean_js_first_log_date'] = pd.to_datetime(df['js_first_log_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ad0c8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(10055)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many rows were not converted\n",
    "df['clean_js_first_log_date'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ccf8e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "js_first_log_date\n",
       "48-03-2016  11:09:36    2\n",
       "03-48-2015  13:11:14    2\n",
       "02-48-2015  15:01:38    2\n",
       "02-48-2015  14:52:42    2\n",
       "29-48-2015  09:44:03    2\n",
       "                       ..\n",
       "48-03-2016  00:05:21    1\n",
       "48-12-2015  00:13:18    1\n",
       "18-48-2015  00:19:41    1\n",
       "01-48-2015  00:04:07    1\n",
       "18-48-2015  00:05:50    1\n",
       "Name: count, Length: 3831, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See bad date strings\n",
    "df[df['clean_js_first_log_date'].isna() & df['js_first_log_date'].notna()]['js_first_log_date'].value_counts()\n",
    "\n",
    "# df['clean_js_first_log_date'].isna() - gave all the NaT rows from the 'clean_js_first_log_date' column\n",
    "# df['js_first_log_date'].notna() - give all the rows that are not NULL in 'js_first_log_date'\n",
    "# combining them ensures that we get only invalid values and not NULL values\n",
    "# ['js_first_log_date'] - Pulls out just the original raw date values from those bad rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b51ab51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_3692\\1857134237.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df.loc[mask_start_48, 'clean_js_first_log_date'] = pd.to_datetime(\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Fix pwd_sent_date values starting with '48' → replace '48' with '04', then remove time\n",
    "mask_start_48 = df['js_first_log_date'].str.startswith('48', na=False)\n",
    "df.loc[mask_start_48, 'clean_js_first_log_date'] = pd.to_datetime(\n",
    "    df.loc[mask_start_48, 'js_first_log_date']\n",
    "    .str.replace(r'^48', '04', regex=True)       # replace starting 48 with 04\n",
    "    .str.extract(r'(\\d{2}-\\d{2}-\\d{4})')[0],      # extract only the date part\n",
    "    errors='coerce',\n",
    "    dayfirst=True\n",
    ")\n",
    "\n",
    "# Step 2: Fix values where '48' is in the **middle** (not already handled in step 1), then remove time\n",
    "mask_middle_48 = df['js_first_log_date'].str.contains('48', na=False) & ~mask_start_48\n",
    "df.loc[mask_middle_48, 'clean_js_first_log_date'] = pd.to_datetime(\n",
    "    df.loc[mask_middle_48, 'js_first_log_date']\n",
    "    .str.replace('--', '-', regex=False)  # fix double hyphens\n",
    "    .str.replace(r'-(48)-', '-08-', regex=True)\n",
    "    .str.extract(r'(\\d{2}-\\d{2}-\\d{4})')[0],\n",
    "    errors='coerce',\n",
    "    dayfirst=True\n",
    ")\n",
    "\n",
    "# Step 3: Fix values with '48' at both start and middle (but NOT those already handled in step 1 and 2)\n",
    "mask_both_48 = df['js_first_log_date'].str.startswith('48', na=False) & df['js_first_log_date'].str.contains('48', na=False)\n",
    "df.loc[mask_both_48, 'clean_js_first_log_date'] = pd.to_datetime(\n",
    "    df.loc[mask_both_48, 'js_first_log_date']\n",
    "    .str.replace(r'^48', '08', regex=True)\n",
    "    .str.replace(r'-(48)-', '-08-', regex=True)\n",
    "    .str.extract(r'(\\d{2}-\\d{2}-\\d{4})')[0],\n",
    "    errors='coerce',\n",
    "    dayfirst=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "751b3a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(6204)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_js_first_log_date'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b8154ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See bad date strings\n",
    "df[df['clean_js_first_log_date'].isna() & df['js_first_log_date'].notna()]['js_first_log_date'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53947c07",
   "metadata": {},
   "source": [
    "Since the number of NULL is still shown 6204 but the above code to get non-null invalid values is showing nothing<br>\n",
    "**This means that the remaining 6204 rows are NULL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b6280c",
   "metadata": {},
   "source": [
    "#### Handle final_submittion_date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a4d58bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valid dates will be converted properly to yyyy-mm-dd format\n",
    "df['clean_final_submittion_date'] = pd.to_datetime(df['final_submittion_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c4d5340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(7638)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many rows were not converted\n",
    "df['clean_final_submittion_date'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87ab8913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "final_submittion_date\n",
       "48-02-2016  14:59:36    2\n",
       "48-02-2016  11:00:45    2\n",
       "48-03-2016  12:12:26    2\n",
       "48-03-2016  48:56:30    2\n",
       "14-48-2015  06:44:13    2\n",
       "                       ..\n",
       "07-48-2015  14:12:28    1\n",
       "19-48-2015  48:06:23    1\n",
       "20-48-2015  48:20:04    1\n",
       "21-48-2015  48:20:51    1\n",
       "09-48-2015  00:48:44    1\n",
       "Name: count, Length: 4119, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See bad date strings\n",
    "df[df['clean_final_submittion_date'].isna() & df['final_submittion_date'].notna()]['final_submittion_date'].value_counts()\n",
    "\n",
    "# df['clean_final_submittion_date'].isna() - gave all the NaT rows from the 'clean_final_submittion_date' column\n",
    "# df['final_submittion_date'].notna() - give all the rows that are not NULL in 'final_submittion_date'\n",
    "# combining them ensures that we get only invalid values and not NULL values\n",
    "# ['final_submittion_date'] - Pulls out just the original raw date values from those bad rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78c0f2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Fix final_submittion_date values starting with '48' → replace '48' with '04', then remove time\n",
    "mask_start_48 = df['final_submittion_date'].str.startswith('48', na=False)\n",
    "df.loc[mask_start_48, 'clean_final_submittion_date'] = pd.to_datetime(\n",
    "    df.loc[mask_start_48, 'final_submittion_date']\n",
    "    .str.replace(r'^48', '04', regex=True)       # replace starting 48 with 04\n",
    "    .str.extract(r'(\\d{2}-\\d{2}-\\d{4})')[0],      # extract only the date part\n",
    "    errors='coerce',\n",
    "    dayfirst=True\n",
    ")\n",
    "\n",
    "# Step 2: Fix values where '48' is in the **middle** (not already handled in step 1), then remove time\n",
    "mask_middle_48 = df['final_submittion_date'].str.contains('48', na=False) & ~mask_start_48\n",
    "df.loc[mask_middle_48, 'clean_final_submittion_date'] = pd.to_datetime(\n",
    "    df.loc[mask_middle_48, 'final_submittion_date']\n",
    "    .str.replace('--', '-', regex=False)  # fix double hyphens\n",
    "    .str.replace(r'-(48)-', '-08-', regex=True)\n",
    "    .str.extract(r'(\\d{2}-\\d{2}-\\d{4})')[0],\n",
    "    errors='coerce',\n",
    "    dayfirst=True\n",
    ")\n",
    "\n",
    "# Step 3: Fix values with '48' at both start and middle (but NOT those already handled in step 1 and 2)\n",
    "mask_both_48 = df['final_submittion_date'].str.startswith('48', na=False) & df['final_submittion_date'].str.contains('48', na=False)\n",
    "df.loc[mask_both_48, 'clean_final_submittion_date'] = pd.to_datetime(\n",
    "    df.loc[mask_both_48, 'final_submittion_date']\n",
    "    .str.replace(r'^48', '08', regex=True)\n",
    "    .str.replace(r'-(48)-', '-08-', regex=True)\n",
    "    .str.extract(r'(\\d{2}-\\d{2}-\\d{4})')[0],\n",
    "    errors='coerce',\n",
    "    dayfirst=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a76f832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(3510)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_final_submittion_date'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['clean_final_submittion_date'].isna() & df['final_submittion_date'].notna()]['final_submittion_date'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78093f3b",
   "metadata": {},
   "source": [
    "Since the number of NULL is still shown 3510 but the above code to get non-null invalid values is showing nothing<br>\n",
    "**This means that the remaining 3510 rows are NULL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def152e5",
   "metadata": {},
   "source": [
    "#### Handle insertdate column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cfc1e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valid dates will be converted properly to yyyy-mm-dd format\n",
    "df['clean_insertdate'] = pd.to_datetime(df['insertdate'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(4121)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many rows were not converted\n",
    "df['clean_insertdate'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8496891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "insertdate\n",
       "48-03-2016  00:00:00    338\n",
       "48-02-2016  00:00:00    303\n",
       "48-48-2015  00:00:00    130\n",
       "13-48-2015  00:00:00    126\n",
       "48-05-2015  00:00:00    120\n",
       "04-48-2015  00:00:00    113\n",
       "12-48-2015  00:00:00    112\n",
       "11-48-2015  00:00:00    108\n",
       "23-48-2015  00:00:00    106\n",
       "26-48-2015  00:00:00    105\n",
       "14-48-2015  00:00:00    104\n",
       "21-48-2015  00:00:00    102\n",
       "16-48-2015  00:00:00    101\n",
       "20-48-2015  00:00:00    100\n",
       "18-48-2015  00:00:00    100\n",
       "08-48-2015  00:00:00     99\n",
       "19-48-2015  00:00:00     99\n",
       "25-48-2015  00:00:00     98\n",
       "01-48-2015  00:00:00     98\n",
       "22-48-2015  00:00:00     97\n",
       "06-48-2015  00:00:00     96\n",
       "27-48-2015  00:00:00     96\n",
       "07-48-2015  00:00:00     93\n",
       "09-48-2015  00:00:00     93\n",
       "31-48-2015  00:00:00     90\n",
       "15-48-2015  00:00:00     90\n",
       "28-48-2015  00:00:00     87\n",
       "24-48-2015  00:00:00     84\n",
       "48-12-2015  00:00:00     81\n",
       "29-48-2015  00:00:00     80\n",
       "48-06-2015  00:00:00     78\n",
       "17-48-2015  00:00:00     76\n",
       "02-48-2015  00:00:00     75\n",
       "03-48-2015  00:00:00     74\n",
       "30-48-2015  00:00:00     74\n",
       "05-48-2015  00:00:00     70\n",
       "48-07-2015  00:00:00     64\n",
       "48-08-2015  00:00:00     61\n",
       "48-11-2015  00:00:00     50\n",
       "48-01-2016  00:00:00     50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See bad date strings\n",
    "df[df['clean_insertdate'].isna() & df['insertdate'].notna()]['insertdate'].value_counts()\n",
    "\n",
    "# df['clean_insertdate'].isna() - gave all the NaT rows from the 'clean_insertdate' column\n",
    "# df['insertdate'].notna() - give all the rows that are not NULL in 'insertdate'\n",
    "# combining them ensures that we get only invalid values and not NULL values\n",
    "# ['insertdate'] - Pulls out just the original raw date values from those bad rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "558659a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Fix insertdate values starting with '48' → replace '48' with '04', then remove time\n",
    "mask_start_48 = df['insertdate'].str.startswith('48', na=False)\n",
    "df.loc[mask_start_48, 'clean_insertdate'] = pd.to_datetime(\n",
    "    df.loc[mask_start_48, 'insertdate']\n",
    "    .str.replace(r'^48', '04', regex=True)       # replace starting 48 with 04\n",
    "    .str.extract(r'(\\d{2}-\\d{2}-\\d{4})')[0],      # extract only the date part\n",
    "    errors='coerce',\n",
    "    dayfirst=True\n",
    ")\n",
    "\n",
    "# Step 2: Fix values where '48' is in the **middle** (not already handled in step 1), then remove time\n",
    "mask_middle_48 = df['insertdate'].str.contains('48', na=False) & ~mask_start_48\n",
    "df.loc[mask_middle_48, 'clean_insertdate'] = pd.to_datetime(\n",
    "    df.loc[mask_middle_48, 'insertdate']\n",
    "    .str.replace('--', '-', regex=False)  # fix double hyphens\n",
    "    .str.replace(r'-(48)-', '-08-', regex=True)\n",
    "    .str.extract(r'(\\d{2}-\\d{2}-\\d{4})')[0],\n",
    "    errors='coerce',\n",
    "    dayfirst=True\n",
    ")\n",
    "\n",
    "# Step 3: Fix values with '48' at both start and middle (but NOT those already handled in step 1 and 2)\n",
    "mask_both_48 = df['insertdate'].str.startswith('48', na=False) & df['insertdate'].str.contains('48', na=False)\n",
    "df.loc[mask_both_48, 'clean_insertdate'] = pd.to_datetime(\n",
    "    df.loc[mask_both_48, 'insertdate']\n",
    "    .str.replace(r'^48', '08', regex=True)\n",
    "    .str.replace(r'-(48)-', '-08-', regex=True)\n",
    "    .str.extract(r'(\\d{2}-\\d{2}-\\d{4})')[0],\n",
    "    errors='coerce',\n",
    "    dayfirst=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bde69ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_insertdate'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959159e3",
   "metadata": {},
   "source": [
    "#### Handle Dob column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72c8d128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valid dates will be converted properly to yyyy-mm-dd format\n",
    "df['clean_Dob'] = pd.to_datetime(df['Dob'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22d1e42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(94063)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many rows were not converted\n",
    "df['clean_Dob'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4a0239b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dob\n",
       "48-07-1992    10\n",
       "48-07-1994     9\n",
       "48-07-1997     8\n",
       "48-07-1990     8\n",
       "48-08-1994     7\n",
       "              ..\n",
       "07-48-1992     1\n",
       "48-12-1991     1\n",
       "48-06-1989     1\n",
       "48-06-1980     1\n",
       "48-09-1987     1\n",
       "Name: count, Length: 257, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See bad date strings\n",
    "df[df['clean_Dob'].isna() & df['Dob'].notna()]['Dob'].value_counts()\n",
    "\n",
    "# df['clean_Dob'].isna() - gave all the NaT rows from the 'clean_Dob' column\n",
    "# df['Dob'].notna() - give all the rows that are not NULL in 'Dob'\n",
    "# combining them ensures that we get only invalid values and not NULL values\n",
    "# ['Dob'] - Pulls out just the original raw date values from those bad rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5059c392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Fix Dob values starting with '48' → replace '48' with '04', then remove time\n",
    "mask_start_48 = df['Dob'].str.startswith('48', na=False)\n",
    "df.loc[mask_start_48, 'Dob'] = pd.to_datetime(\n",
    "    df.loc[mask_start_48, 'Dob']\n",
    "    .str.replace(r'^48', '04', regex=True),       # replace starting 48 with 04\n",
    "    errors='coerce',\n",
    "    dayfirst=True\n",
    ")\n",
    "\n",
    "# Step 2: Fix values where '48' is in the **middle** (not already handled in step 1), then remove time\n",
    "mask_middle_48 = df['Dob'].str.contains('48', na=False) & ~mask_start_48\n",
    "df.loc[mask_middle_48, 'clean_Dob'] = pd.to_datetime(\n",
    "    df.loc[mask_middle_48, 'Dob']\n",
    "    .str.replace('--', '-', regex=False)  # fix double hyphens\n",
    "    .str.replace(r'-(48)-', '-08-', regex=True),\n",
    "    errors='coerce',\n",
    "    dayfirst=True\n",
    ")\n",
    "\n",
    "# Step 3: Fix values with '48' at both start and middle (but NOT those already handled in step 1 and 2)\n",
    "mask_both_48 = df['Dob'].str.startswith('48', na=False) & df['Dob'].str.contains('48', na=False)\n",
    "df.loc[mask_both_48, 'clean_Dob'] = pd.to_datetime(\n",
    "    df.loc[mask_both_48, 'Dob']\n",
    "    .str.replace(r'^48', '08', regex=True)\n",
    "    .str.replace(r'-(48)-', '-08-', regex=True),\n",
    "    errors='coerce',\n",
    "    dayfirst=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c75ddccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(93905)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_Dob'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14f27003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['clean_final_submittion_date'].isna() & df['final_submittion_date'].notna()]['final_submittion_date'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7064a772",
   "metadata": {},
   "source": [
    "Since the number of NULL is still shown 93606 but the above code to get non-null invalid values is showing nothing<br>\n",
    "**This means that the remaining 93606 rows are NULL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a473de5",
   "metadata": {},
   "source": [
    "#### Handle LastloginDate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31afa26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valid dates will be converted properly to yyyy-mm-dd format\n",
    "df['clean_LastloginDate'] = pd.to_datetime(df['LastloginDate'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92d8b3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(55127)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many rows were not converted\n",
    "df['clean_LastloginDate'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8658f3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LastloginDate\n",
       "22-48-2021  16:14:24    1\n",
       "13-48-2021  22:34:18    1\n",
       "48-08-2022  23:37:46    1\n",
       "01-48-2022  17:24:18    1\n",
       "02-48-2021  20:57:43    1\n",
       "                       ..\n",
       "48-04-2018  17:32:47    1\n",
       "21-48-2016  18:23:32    1\n",
       "21-48-2021  14:51:38    1\n",
       "48-04-2025  11:51:05    1\n",
       "24-48-2021  23:06:24    1\n",
       "Name: count, Length: 1873, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See bad date strings\n",
    "df[df['clean_LastloginDate'].isna() & df['LastloginDate'].notna()]['LastloginDate'].value_counts()\n",
    "\n",
    "# df['clean_LastloginDate'].isna() - gave all the NaT rows from the 'clean_LastloginDate' column\n",
    "# df['LastloginDate'].notna() - give all the rows that are not NULL in 'LastloginDate'\n",
    "# combining them ensures that we get only invalid values and not NULL values\n",
    "# ['LastloginDate'] - Pulls out just the original raw date values from those bad rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "08acc541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Fix LastloginDate values starting with '48' → replace '48' with '04', then remove time\n",
    "mask_start_48 = df['LastloginDate'].str.startswith('48', na=False)\n",
    "df.loc[mask_start_48, 'clean_LastloginDate'] = pd.to_datetime(\n",
    "    df.loc[mask_start_48, 'LastloginDate']\n",
    "    .str.replace(r'^48', '04', regex=True)       # replace starting 48 with 04\n",
    "    .str.extract(r'(\\d{2}-\\d{2}-\\d{4})')[0],      # extract only the date part\n",
    "    errors='coerce',\n",
    "    dayfirst=True\n",
    ")\n",
    "\n",
    "# Step 2: Fix values where '48' is in the **middle** (not already handled in step 1), then remove time\n",
    "mask_middle_48 = df['LastloginDate'].str.contains('48', na=False) & ~mask_start_48\n",
    "df.loc[mask_middle_48, 'clean_LastloginDate'] = pd.to_datetime(\n",
    "    df.loc[mask_middle_48, 'LastloginDate']\n",
    "    .str.replace('--', '-', regex=False)  # fix double hyphens\n",
    "    .str.replace(r'-(48)-', '-08-', regex=True)\n",
    "    .str.extract(r'(\\d{2}-\\d{2}-\\d{4})')[0],\n",
    "    errors='coerce',\n",
    "    dayfirst=True\n",
    ")\n",
    "\n",
    "# Step 3: Fix values with '48' at both start and middle (but NOT those already handled in step 1 and 2)\n",
    "mask_both_48 = df['LastloginDate'].str.startswith('48', na=False) & df['LastloginDate'].str.contains('48', na=False)\n",
    "df.loc[mask_both_48, 'clean_LastloginDate'] = pd.to_datetime(\n",
    "    df.loc[mask_both_48, 'LastloginDate']\n",
    "    .str.replace(r'^48', '08', regex=True)\n",
    "    .str.replace(r'-(48)-', '-08-', regex=True)\n",
    "    .str.extract(r'(\\d{2}-\\d{2}-\\d{4})')[0],\n",
    "    errors='coerce',\n",
    "    dayfirst=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a1add4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(53254)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_LastloginDate'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f42875e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['clean_LastloginDate'].isna() & df['LastloginDate'].notna()]['LastloginDate'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c06717",
   "metadata": {},
   "source": [
    "Since the number of NULL is still shown 53254 but the above code to get non-null invalid values is showing nothing<br>\n",
    "**This means that the remaining 53254 rows are NULL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a29e2e5",
   "metadata": {},
   "source": [
    "#### Handle Aadhar_verify_dt column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3140f6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valid dates will be converted properly to yyyy-mm-dd format\n",
    "df['clean_Aadhar_verify_dt'] = pd.to_datetime(df['Aadhar_verify_dt'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f7e2ecd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(93929)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many rows were not converted\n",
    "df['clean_Aadhar_verify_dt'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "54673f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Aadhar_verify_dt\n",
       "48-03-2023  13:33:34    1\n",
       "12-48-2023  11:09:57    1\n",
       "26-48-2023  14:39:50    1\n",
       "48-09-2024  08:02:39    1\n",
       "48-03-2023  48:17:53    1\n",
       "                       ..\n",
       "01-48-2023  19:54:38    1\n",
       "11-48-2023  17:52:08    1\n",
       "48-07-2023  13:32:28    1\n",
       "26-48-2023  18:57:30    1\n",
       "48-06-2023  16:55:52    1\n",
       "Name: count, Length: 323, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See bad date strings\n",
    "df[df['clean_Aadhar_verify_dt'].isna() & df['Aadhar_verify_dt'].notna()]['Aadhar_verify_dt'].value_counts()\n",
    "\n",
    "# df['clean_Aadhar_verify_dt'].isna() - gave all the NaT rows from the 'clean_Aadhar_verify_dt' column\n",
    "# df['Aadhar_verify_dt'].notna() - give all the rows that are not NULL in 'LastloginDate'\n",
    "# combining them ensures that we get only invalid values and not NULL values\n",
    "# ['Aadhar_verify_dt'] - Pulls out just the original raw date values from those bad rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6d2c4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Fix Aadhar_verify_dt values starting with '48' → replace '48' with '04', then remove time\n",
    "mask_start_48 = df['Aadhar_verify_dt'].str.startswith('48', na=False)\n",
    "df.loc[mask_start_48, 'clean_Aadhar_verify_dt'] = pd.to_datetime(\n",
    "    df.loc[mask_start_48, 'Aadhar_verify_dt']\n",
    "    .str.replace(r'^48', '04', regex=True)       # replace starting 48 with 04\n",
    "    .str.extract(r'(\\d{2}-\\d{2}-\\d{4})')[0],      # extract only the date part\n",
    "    errors='coerce',\n",
    "    dayfirst=True\n",
    ")\n",
    "\n",
    "# Step 2: Fix values where '48' is in the **middle** (not already handled in step 1), then remove time\n",
    "mask_middle_48 = df['Aadhar_verify_dt'].str.contains('48', na=False) & ~mask_start_48\n",
    "df.loc[mask_middle_48, 'clean_Aadhar_verify_dt'] = pd.to_datetime(\n",
    "    df.loc[mask_middle_48, 'Aadhar_verify_dt']\n",
    "    .str.replace('--', '-', regex=False)  # fix double hyphens\n",
    "    .str.replace(r'-(48)-', '-08-', regex=True)\n",
    "    .str.extract(r'(\\d{2}-\\d{2}-\\d{4})')[0],\n",
    "    errors='coerce',\n",
    "    dayfirst=True\n",
    ")\n",
    "\n",
    "# Step 3: Fix values with '48' at both start and middle (but NOT those already handled in step 1 and 2)\n",
    "mask_both_48 = df['Aadhar_verify_dt'].str.startswith('48', na=False) & df['Aadhar_verify_dt'].str.contains('48', na=False)\n",
    "df.loc[mask_both_48, 'clean_Aadhar_verify_dt'] = pd.to_datetime(\n",
    "    df.loc[mask_both_48, 'Aadhar_verify_dt']\n",
    "    .str.replace(r'^48', '08', regex=True)\n",
    "    .str.replace(r'-(48)-', '-08-', regex=True)\n",
    "    .str.extract(r'(\\d{2}-\\d{2}-\\d{4})')[0],\n",
    "    errors='coerce',\n",
    "    dayfirst=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a24545f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(93606)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_Aadhar_verify_dt'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ebe2b5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['clean_Aadhar_verify_dt'].isna() & df['Aadhar_verify_dt'].notna()]['Aadhar_verify_dt'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e313dd",
   "metadata": {},
   "source": [
    "Since the number of NULL is still shown 93606 but the above code to get non-null invalid values is showing nothing<br>\n",
    "**This means that the remaining 93606 rows are NULL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7a7f73",
   "metadata": {},
   "source": [
    "### Format Categorical Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78ed41e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pwd_sent_mode\n",
       "B    89399\n",
       "M    10601\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pwd_sent_mode'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58595b4f",
   "metadata": {},
   "source": [
    "- B -> Batch i.e. generated by auto-suggest medium\n",
    "- M -> Manual i.e. user-generated by specific individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c5831cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prf_submitted\n",
       "Y      44261\n",
       "NaN    29566\n",
       "D      26173\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['prf_submitted'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be50ce23",
   "metadata": {},
   "source": [
    "- Y -> Yes i.e. complete profile created and submitted\n",
    "- D -> Draft i.e. profile is saved but not submitted\n",
    "- NaN -> Null i.e. profile not created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fa244f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lock\n",
       "0    100000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lock'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0f7c0b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoginAttempts\n",
       "0     91480\n",
       "1      4410\n",
       "2      1851\n",
       "3       812\n",
       "4       680\n",
       "5       332\n",
       "6       191\n",
       "7       121\n",
       "8        64\n",
       "9        58\n",
       "48        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['LoginAttempts'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b14f879b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userActiveDeactive\n",
       "NaN    84845\n",
       "1.0     7869\n",
       "0.0     7286\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['userActiveDeactive'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "32a2e4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userActiveDeactiveToken\n",
       "NaN                                 92131\n",
       "54a367d629152b720749e187b3eaa11b       20\n",
       "07563a3fe3bbe7e3ba84431ad9d055af       17\n",
       "a3d68b461bd9d3533ee1dd3ce4628ed4       16\n",
       "432aca3a1e345e339f35a30c8f65edce       16\n",
       "                                    ...  \n",
       "0bb4aec1748521c12ee76289d9440817        1\n",
       "2f37d10131f2a483a8dd005b3d14b0d9        1\n",
       "cd00692c3bfe59267d5ecfac5348286c        1\n",
       "4b6538a44a1dfdc2b83477cd76dee98e        1\n",
       "b6a1085a27ab7bff7550f8a3bd017df8        1\n",
       "Name: count, Length: 1093, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['userActiveDeactiveToken'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6621898d",
   "metadata": {},
   "source": [
    "#### Create New Columns (Feature Engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9211563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "today_date = pd.to_datetime('today')  # includes time\n",
    "\n",
    "df['account_age_days'] = (today_date - df['clean_insertdate']).dt.days # get only the number of days\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dacc3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_verified'] = df['AadharFlag'].apply(lambda x: 1 if x == 'Y' else 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58abf176",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_active_user'] = df['LoginAttempts'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d834d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['has_logged_in'] = df['js_first_log_date'].apply(lambda x: 1 if pd.notna(x) else 0) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edec181e",
   "metadata": {},
   "source": [
    "### Checking and Handling Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7f545fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(449)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['js_unique_id'].duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111cbc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique ids which appeared more than once\n",
    "df['js_unique_id'].value_counts()[df['js_unique_id'].value_counts() > 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eb3c8320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>js_unique_id</th>\n",
       "      <th>eng_name_of_js</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [js_unique_id, eng_name_of_js, count]\n",
       "Index: []"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the same id is allocated to the same person\n",
    "df.groupby(['js_unique_id', 'eng_name_of_js']).size().reset_index(name='count').query('count > 1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03876a5",
   "metadata": {},
   "source": [
    "#### Summary of Duplicate Handling\n",
    "There are **449** such **'js_unique_id'** which are given to 2 completely different persons and it can lead to serious issues if not handled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c3f5f",
   "metadata": {},
   "source": [
    "### Final Summary after preprocessing\n",
    "\n",
    "| Column                                                                   | Reason to leave as it is & not use in analysis   |\n",
    "| ------------------------------------------------------------------------ | ------------------------------------------------ |\n",
    "| `usernameEdistrict`                                                      | 100% null                                        |\n",
    "| `Is_Archival`, `ArogyaSetu`, `satyapan_done`, `CheckFlag`, `AadharFlag`, `old_reg_YN`, `lock` | Single value only           |\n",
    "| `NewPassword`, `NewPassFlag`, `userActiveDeactiveToken`, `generated_1st_pwd`, `current_pwd`| Sensitive or hashed passwords  |\n",
    "| `aft_satyapan_login_dt`, `sw_unique_id_create_date`                      | Data in wrong format expected date but is time   |\n",
    "| `Dob`, `gender`, `Aadhar_verify_dt`, `csc_request_key`, `csc_user_type`  | More than 93000 rows are missing                 |\n",
    "| `daily_serial_no`                                                        | Likely sequential and not useful                 |\n",
    "| `username`, `sw_unique_id`                                               | Not sure what it shows                           |\n",
    "| `question_id`, `security_answer`, `userActiveDeactive`             | Not relevant unless you're analyzing security patterns |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce52db7",
   "metadata": {},
   "source": [
    "### Renaming the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76a46fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\n",
    "    'eng_name_of_js': 'js_name',\n",
    "    'phone_no_js': 'js_phoneNo', \n",
    "    'js_browser': 'js_browser_version',\n",
    "    'js_browser_ver' : 'js_browser_name'\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4958ad",
   "metadata": {},
   "source": [
    "#### Saving as a cleaned and preprocessed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cf9adaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_save = ['js_unique_id', 'js_name', 'js_phoneNo', 'js_email', 'js_request_ip_address', 'pwd_sent_mode', 'js_browser_name', 'js_browser_version', 'prf_submitted', 'satyapan_done', 'LoginAttempts', 'clean_request_date', 'clean_pwd_sent_date', 'clean_js_first_log_date', 'clean_final_submittion_date', 'clean_insertdate',\n",
    "       'clean_LastloginDate', 'clean_Aadhar_verify_dt', 'account_age_days',\n",
    "       'is_verified', 'is_active_user', 'has_logged_in']\n",
    "\n",
    "df[columns_to_save].to_csv('Preprocessed_DataJobSeeker.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
